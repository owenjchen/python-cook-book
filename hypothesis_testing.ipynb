{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ba3a4fd-46f4-4ba1-a2ab-9508539a1592",
   "metadata": {},
   "source": [
    "# Hypothesis Testing with Python\n",
    "\n",
    "* Author: Owen Chen\n",
    "* Date: 4/17/2022\n",
    "\n",
    "Using the following packages:\n",
    "- scipy.stats\n",
    "- statsmodels.stats\n",
    "- sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c7eac3c3-af5a-44a4-b9b0-60f99a1fc098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import statsmodels.stats.proportion\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ad3f4-e531-4608-8bb6-5548c4e8c488",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. One sample mean test  \n",
    " \n",
    "### Method 1 - scipy.stats.ttest_1samp()\n",
    "\n",
    "* scipy.stats.ttest_1samp(a, popmean,alternative='two-sided')\n",
    "\n",
    "with parameter alternative determines the alternative hypothesis:\n",
    "\n",
    "- alternative='two-sided' as default for two-sided test\n",
    "- alternative='greater'  for right-sided test\n",
    "- alternative='less' for left-sided test\n",
    "\n",
    "### Method 2 - calculate z_score and p_value by hand in Python\n",
    "\n",
    "To find the p-value associated with a z-score in Python, we can use the scipy.stats.norm.sf() function, which uses the following syntax:\n",
    "\n",
    "* scipy.stats.norm.sf(abs(x))\n",
    "or \n",
    "* scipy.stats.norm.cdf(x)\n",
    "\n",
    "where:\n",
    "x: The z-score\n",
    "The following examples illustrate how to find the p-value associated with a z-score for a left-tailed test, right-tailed test, and a two-tailed test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5af4aa61-3de9-445e-bf73-5f2074ba0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One sample mean test \n",
    "def one_sample_mean_test(data, mu,alternative='two-sided'):\n",
    "    '''One-sample test of mean\n",
    "    Parameters:\n",
    "    - data  is an array or panda series\n",
    "    - mu is the population mean\n",
    "    Hypothesis is that the mean of the sample data is the same as population mean\n",
    "\n",
    "    Returns:\n",
    "    t_stat, p_value\n",
    "    '''\n",
    "    \n",
    "    x = np.array(data)       \n",
    "    return   scipy.stats.ttest_1samp(data, popmean=mu,alternative=alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b93eaa28-48fc-4e90-a2c7-e45aa0614fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One sample mean test \n",
    "# calculate z_score and p_value by hand\n",
    "# Two sided-test\n",
    "def one_sample_mean_test2(data, mu,alternative='two-sided'):\n",
    "    '''One-sample test of mean\n",
    "    Parameters:\n",
    "    - data  is an array or panda series\n",
    "    - mu is the population mean\n",
    "    Hypothesis is that the mean of the sample data is the same as population mean\n",
    "\n",
    "    Returns:\n",
    "    t_stat, p_value\n",
    "    '''\n",
    "    x = np.array(data)\n",
    "    x_size=np.size(x)\n",
    "    if x_size <=1:\n",
    "        print(\"Error: input data size is \", x_size)\n",
    "        return None\n",
    "    # Delta Degree of freedom\n",
    "    ddof =1\n",
    "    # Degree of freedom \n",
    "    df = x_size - ddof\n",
    "    \n",
    "    x_std = np.std(x, ddof=ddof)  \n",
    "    t_stat = np.sum(x-mu)/x_std/np.sqrt(x_size)\n",
    "    # sf = 1 - cdf\n",
    "\n",
    "    if alternative == 'greater': \n",
    "        # 1-cdf = sf\n",
    "        p_value = sp.stats.t.sf(t_stat, df = df)\n",
    "    elif alternative == 'less':  \n",
    "        #cdf\n",
    "        p_value = sp.stats.t.cdf(t_stat, df = df)\n",
    "    else:\n",
    "        # default two-side:\n",
    "        # 2*(1-cdf) = 2*sf\n",
    "        p_value = 2*sp.stats.t.sf(abs(t_stat), df = df) \n",
    "        \n",
    "    return t_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "022a3d47-2e40-466a-b8ce-6707805d9470",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.04433508, 4.257188  , 3.4875755 , 3.77211059, 4.72623162,\n",
       "       3.03832596, 2.69845169, 2.5819029 , 4.59528886, 4.74234099,\n",
       "       4.98161177, 2.30833295, 2.41333026, 5.04687774, 2.18393775,\n",
       "       1.70330775, 2.66077359, 4.10997902, 5.11139856, 4.48284012,\n",
       "       5.66614361, 2.3230905 , 4.79080929, 3.59790108, 3.83863411,\n",
       "       3.80557731, 4.88592699, 5.75603008, 3.30051588, 4.74907305,\n",
       "       6.18468444, 4.42221224, 3.28081427, 4.44603437, 2.03636916,\n",
       "       4.62188784, 3.57443597, 2.43344146, 3.98267852, 3.99750737,\n",
       "       4.34885381, 5.70478692, 3.51697397, 5.05724655, 4.47820459,\n",
       "       3.91855435, 5.07786684, 5.16576974, 2.81892532, 5.73913964,\n",
       "       4.17335044, 4.85357609, 1.62456745, 3.30035839, 5.83198097,\n",
       "       3.54189561, 2.11012603, 3.8246223 , 3.88132273, 3.89647199,\n",
       "       5.08211402, 3.44440532, 3.35111754, 4.28559806, 3.50870679,\n",
       "       3.4898637 , 4.31136518, 3.80561105, 3.16897267, 2.48059101,\n",
       "       4.65096233, 3.07618241, 4.52329761, 5.31703033, 3.17344861,\n",
       "       3.49252113, 3.90381233, 2.01973006, 3.69564671, 4.84193938,\n",
       "       3.43742317, 4.52205535, 4.40509073, 3.9112431 , 3.61088025,\n",
       "       1.71507264, 3.27667932, 3.30986937, 2.77430739, 4.15694109,\n",
       "       2.70896962, 5.42822315, 3.796669  , 3.88539345, 5.38092306,\n",
       "       2.75780297, 4.5504553 , 3.35927338, 4.26466389, 4.06359777])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a Gaussian series\n",
    "mu = 4.0\n",
    "arraynormal = np.random.normal(loc=mu, scale=1, size=100)\n",
    "arraynormal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182bba3-7334-4cb9-b8ad-38106350e13c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1) One sample mean - two-tailed test \n",
    "\n",
    "population mean = 4.0\n",
    "\n",
    "$H_0: \\mu = 4.0 $   \n",
    "\n",
    "$H_1: \\mu \\neq 4.0 $\n",
    "\n",
    "#### If $\\alpha = 0.05$, we can not reject the null hypothesis $H_0$ since p-value > $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e3f64b14-5b80-48fd-a640-9fc1cb15e484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_sample_mean_test() result: t_stat=-1.0179400025407277, p_value=0.3111876990375008\n",
      "one_sample_mean_test2() result: t_stat=-1.0179400025407324, p_value=0.31118769903749877\n"
     ]
    }
   ],
   "source": [
    "## One sample mean two-tailed test \n",
    "t_stat, p_value = one_sample_mean_test(arraynormal,mu)\n",
    "print(f\"one_sample_mean_test() result: t_stat={t_stat}, p_value={p_value}\")\n",
    "t_stat, p_value = one_sample_mean_test2(arraynormal, mu)\n",
    "print(f\"one_sample_mean_test2() result: t_stat={t_stat}, p_value={p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7919b8b-a39b-43d7-874c-964bad4c8208",
   "metadata": {},
   "source": [
    "### 1.2) One sample mean - right-tailed test \n",
    "population mean = 4.0\n",
    "\n",
    "$H_0: \\mu = 4.0 $   \n",
    "\n",
    "$H_1: \\mu > 4.0 $\n",
    "\n",
    "#### p-value on righ-sided is much higher -  we can not reject the null hypothesis $H_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7fdb4889-3449-475c-a8a9-8d78f1145714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_sample_mean_test() result: t_stat=-1.0179400025407277, p_value=0.8444061504812496\n",
      "one_sample_mean_test2() result: t_stat=-1.0179400025407324, p_value=0.8444061504812506\n"
     ]
    }
   ],
   "source": [
    "## One sample mean righ-tailed test  \n",
    "t_stat, p_value = one_sample_mean_test(arraynormal,mu, alternative='greater')\n",
    "print(f\"one_sample_mean_test() result: t_stat={t_stat}, p_value={p_value}\")\n",
    "t_stat, p_value = one_sample_mean_test2(arraynormal, mu,alternative='greater')\n",
    "print(f\"one_sample_mean_test2() result: t_stat={t_stat}, p_value={p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5290ca-dbee-48a9-acbe-dd897a601634",
   "metadata": {},
   "source": [
    "### 1.3) One sample mean - left-tailed test \n",
    "population mean = 4.0\n",
    "\n",
    "$H_0: \\mu = 4.0 $   \n",
    "\n",
    "$H_1: \\mu < 4.0 $\n",
    "\n",
    "#### p-value on left-sided is lower but we still can not reject the null hypothesis $H_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "64fb0e39-6a10-4933-8989-d3b347255476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_sample_mean_test() result: t_stat=-1.0179400025407277, p_value=0.1555938495187504\n",
      "one_sample_mean_test2() result: t_stat=-1.0179400025407324, p_value=0.15559384951874938\n"
     ]
    }
   ],
   "source": [
    "## One sample mean left-tailed test  \n",
    "t_stat, p_value = one_sample_mean_test(arraynormal,mu, alternative='less')\n",
    "print(f\"one_sample_mean_test() result: t_stat={t_stat}, p_value={p_value}\")\n",
    "t_stat, p_value = one_sample_mean_test2(arraynormal, mu,alternative='less')\n",
    "print(f\"one_sample_mean_test2() result: t_stat={t_stat}, p_value={p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa1d5c2-56b6-486f-9b1d-aa0f938b16c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.  Two Sample Mean Test\n",
    "\n",
    "\n",
    "$H_0: {\\mu}_1 = {\\mu}_2 $   \n",
    "\n",
    "$H_1: {\\mu}_1 \\neq {\\mu}_2 $\n",
    "\n",
    "### Method 1 - scipy.stats.ttest_ind()\n",
    "### Method 2 - calculate t-stat by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "755eb242-2d5e-488a-95e7-d9ebb9d0621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 - Using scipy.stats.ttest_ind()\n",
    "\n",
    "def two_sample_mean_test(data1, data2):\n",
    "    '''Two-sample test of mean\n",
    "    For example, if `data1` is the heights of a group of men, `data2` is the heights of a group of women, and the hypothesis is that the means of men and women are the same, does data support this hypothesis?\n",
    "\n",
    "    Parameters:\n",
    "    data1, data2\n",
    "\n",
    "    Returns:\n",
    "    t_stat, p_value\n",
    "    '''\n",
    "    x, y = np.array(data1), np.array(data2)\n",
    "    return scipy.stats.ttest_ind(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1b6cd4aa-e408-45bd-ac64-b1bb4e6f9983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate t-stat by hand\n",
    "\n",
    "def two_sample_mean_test2(data1, data2):\n",
    "    '''Two-sample test of mean\n",
    "    For example, if `data1` is the heights of a group of men, `data2` is the heights of a group of women, and the hypothesis is that the means of men and women are the same, does data support this hypothesis?\n",
    "\n",
    "    Parameters:\n",
    "    data1, data2\n",
    "\n",
    "    Returns:\n",
    "    t_score, p_value\n",
    "    '''\n",
    "    x, y = np.array(data1), np.array(data2)\n",
    "    x_size=np.size(x)\n",
    "    y_size=np.size(y)    \n",
    "    if x_size <=1 or y_size <=1:\n",
    "        print(f\"Error: input data size incorrect:  size(data1) ={x_size},  size(data2)={y_size}\")\n",
    "        return None\n",
    "    # Delta Degree of freedom\n",
    "    ddof =1\n",
    "    # Degree of freedom \n",
    "    \n",
    "    x_var = np.var(x, ddof=1) \n",
    "    y_var = np.var(y, ddof=1) \n",
    "    x_y_mean = np.mean(x) - np.mean(y)\n",
    "    df = x_size + y_size - 2\n",
    "    xy_std = np.sqrt(((x_size-1)*x_var+(y_size-1)*y_var)/df)\n",
    "    t_stat = x_y_mean /xy_std/np.sqrt(1/x_size + 1/y_size)\n",
    "    p_value = 2*sp.stats.t.sf(abs(t_stat), df = df) \n",
    "        \n",
    "    return t_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bf4a01df-691a-4b11-8895-f4f82020dac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_sample_mean_test(x, y) result: t_stat=-0.03486271913712174, p_value=0.9722243290782255\n",
      "two_sample_mean_test2(x, y) result: t_stat=-0.034862719137121745, p_value=0.9722243290782255\n"
     ]
    }
   ],
   "source": [
    "# Generate two Gaussian series\n",
    "mu = 4.0\n",
    "x = np.random.normal(loc=mu, scale=1, size=100)\n",
    "y = np.random.normal(loc=mu, scale=1, size=100)\n",
    "## two sample mean test\n",
    "t_stat, p_value = two_sample_mean_test(x, y)\n",
    "print(f\"two_sample_mean_test(x, y) result: t_stat={t_stat}, p_value={p_value}\")\n",
    "t_stat2, p_value2 = two_sample_mean_test2(x, y)\n",
    "print(f\"two_sample_mean_test2(x, y) result: t_stat={t_stat2}, p_value={p_value2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cf846e-e446-4bee-be6a-c5cd59b18f82",
   "metadata": {},
   "source": [
    "## 3. Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fecd0d10-4998-44ec-8a55-f17d0d2d9f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/15033511/compute-a-confidence-interval-from-sample-data\n",
    "# Method 1 - using scipy.stats.t.ppf  Percent point function (inverse of cdf)\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    df = len(a) -1\n",
    "    mu, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., df)\n",
    "    return mu, [mu-h, mu+h]\n",
    "\n",
    "#Method 2 - using scipy.stats.t.interva\n",
    "def mean_confidence_interval2(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    df = len(a) -1\n",
    "    mu, se = np.mean(a), scipy.stats.sem(a)    \n",
    "    lb, ub = scipy.stats.t.interval(confidence, df, loc=mu, scale=se)\n",
    "    return mu, [lb, ub]\n",
    "\n",
    "# Method 3 - calculate by hand\n",
    "def mean_confidence_interval3(data, confidence=0.95):\n",
    "    '''One-sample mean confidence interval\n",
    "\n",
    "    For example, if `data` is the heights of a group of men, what is the confidence interval of size `confidence` for the mean of the heights?\n",
    "\n",
    "    Parameters:\n",
    "    data\n",
    "    confidence: float number from (0, 1)\n",
    "\n",
    "    Returns:\n",
    "    confidence_interval\n",
    "    '''\n",
    "    a = np.array(data)\n",
    "    n = len(a)\n",
    "    mu = a.mean()\n",
    "    sample_standard_devication = sum((a - mu) ** 2) /  (n-1)\n",
    "    standard_error_of_mean = np.sqrt(sample_standard_devication / n)\n",
    "    alpha = 1 - confidence\n",
    "    #t_critical = scipy.stats.norm.ppf(1 - alpha / 2, )\n",
    "    t_critical = scipy.stats.t.ppf(1 - alpha / 2, n-1)\n",
    "    confidence_interval = [mu - t_critical * standard_error_of_mean,\\\n",
    "        mu + t_critical * standard_error_of_mean]\n",
    "    return mu, confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b9e3879b-587b-42ed-b600-e94ea04d93b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two Gaussian series\n",
    "mu = 4.0\n",
    "x = np.random.normal(loc=mu, scale=1, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "984e5102-33bc-4238-98f5-0d5b42eeae01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method1 - mean_confidence_interval(): (4.202395584697616, [4.019989631676888, 4.384801537718343])\n",
      "method2 - mean_confidence_interval2(): (4.202395584697616, [4.019989631676888, 4.384801537718343])\n",
      "method3 - mean_confidence_interval3(): (4.202395584697616, [4.019989631676888, 4.384801537718343])\n"
     ]
    }
   ],
   "source": [
    "confidence = 0.95\n",
    "print(\"method1 - mean_confidence_interval():\", mean_confidence_interval(x, confidence=confidence))\n",
    "print(\"method2 - mean_confidence_interval2():\", mean_confidence_interval2(x, confidence=confidence))\n",
    "print(\"method3 - mean_confidence_interval3():\", mean_confidence_interval3(x, confidence=confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afbf239-8b7d-4b5c-981a-84aea9a70db3",
   "metadata": {},
   "source": [
    "## 4.  Propotional Tests and Confidence Intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73376d5-48ab-4dc2-ae3a-254413da9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_sample_proportion_confidence_interval(n_successes, n_trials,\n",
    "                                              confidence=0.95):\n",
    "    '''One-sample proportion confidence interval\n",
    "\n",
    "    For example, if `n_successes` out of `n_trials` customers clicked the link, what is the confidence interval of click through rate?\n",
    "\n",
    "    Parameters:\n",
    "    n_successes: number of successes\n",
    "    n_trials: number of trials\n",
    "    confidence: float number from (0, 1)\n",
    "\n",
    "    Returns:\n",
    "    confidence_interval\n",
    "    '''\n",
    "    p_hat = n_successes / n_trials\n",
    "    standard_error_of_mean = np.sqrt(p_hat * (1 - p_hat) / n_trials)\n",
    "    alpha = 1 - confidence\n",
    "    z_critical = scipy.stats.norm.ppf(1 - alpha / 2)\n",
    "    confidence_interval = p_hat - z_critical * standard_error_of_mean, p_hat +\\\n",
    "        z_critical * standard_error_of_mean\n",
    "    return confidence_interval\n",
    "\n",
    "\n",
    "def one_sample_proportion_test(n_successes, n_trials, p_hypo, one_side=False):\n",
    "    '''One-sample proportion significant test\n",
    "\n",
    "    For example, if `n_successes` out of `n_trials` customers clicked the link, and the hypothesis is that the click through rate is `p_hypo`, does data support this hypothesis?\n",
    "\n",
    "    Parameters:\n",
    "    n_successes: number of successes\n",
    "    n_trials: number of trials\n",
    "    p_hypo: hypothetical proportion\n",
    "    one_side: if True, do one side test\n",
    "\n",
    "    Returns:\n",
    "    z_score, p_value\n",
    "    '''\n",
    "    p_hat = n_successes / n_trials\n",
    "    standard_error = np.sqrt(p_hat * (1 - p_hat) / n_trials)\n",
    "    z = (p_hat - p_hypo) / standard_error\n",
    "    p_value = 1 - scipy.stats.norm.cdf(abs(z))\n",
    "    if not one_side:\n",
    "        p_value *= 2\n",
    "    return z, p_value\n",
    "\n",
    "\n",
    "def _one_sample_proportion_test_t(n_successes, n_trials, p_hypo,\n",
    "                                  one_side=False):\n",
    "    a = [1] * n_successes + [0] * (n_trials - n_successes)\n",
    "    return scipy.stats.ttest_1samp(a, popmean=p_hypo)\n",
    "\n",
    "\n",
    "def two_sample_proportion_test(n_successes_1, n_trials_1, n_successes_2,\n",
    "                               n_trials_2):\n",
    "    '''Two-sample proportion significant test\n",
    "\n",
    "    For example, if `n_successes_1` out of `n_trials_1` customers click through on Website Version A, `n_successes_2` out of `n_trials_2` customers click through on Website Version B, and the hypothesis is that the click through rates are the same, does data support this hypothesis?\n",
    "\n",
    "    Parameters:\n",
    "    n_successes_1: number of successes in Test-1\n",
    "    n_trials_1: number of trials in Test-1\n",
    "    n_successes_2: number of successes in Test-2\n",
    "    n_trials_2: number of trials in Test-2\n",
    "\n",
    "    Returns:\n",
    "    z_score, p_value\n",
    "    '''\n",
    "    z, p_value = statsmodels.stats.proportion.proportions_ztest((n_successes_1, n_successes_2), (n_trials_1, n_trials_2))\n",
    "    return z, p_value\n",
    "\n",
    "\n",
    "def multi_sample_mean_test(data_sets):\n",
    "    '''Multi-sample test of mean\n",
    "    For example, if `data1` is the heights of football team A, `data2` is the heights of football team B, `data3` is the heights of football team C, and the hypothesis is that the means of the teams are the same, does data support this hypothesis?\n",
    "\n",
    "    Parameters:\n",
    "    data_sets\n",
    "\n",
    "    Returns:\n",
    "    f_score, p_value\n",
    "    '''\n",
    "    f, p_value = scipy.stats.f_oneway(*data_sets)\n",
    "    return f, p_value\n",
    "\n",
    "\n",
    "def paired_sample_mean_test(data1, data2):\n",
    "    '''Paired-sample test of mean\n",
    "    For example, if `data1` is the heights of a group of men in the morning, `data2` is the heights of the same group of men in the evening (with the same order), and the hypothesis is that the heights of morning and evening are the same, does data support this hypothesis?\n",
    "\n",
    "    Parameters:\n",
    "    data1, data2\n",
    "\n",
    "    Returns:\n",
    "    t_score, p_value\n",
    "\n",
    "    '''\n",
    "    a, b = np.array(data1), np.array(data2)\n",
    "    t, p_value = scipy.stats.ttest_rel(a, b)\n",
    "    return t, p_value\n",
    "\n",
    "\n",
    "def correlation_coef(data1, data2):\n",
    "    '''Correlation coefficient and non-correlation test for two continuous variables\n",
    "    For example, if `data1` is the English test score of a group of students, `data2` is the Math test score of the same group of students, are the two scores correlated? Null hypothesis is non-correlation.\n",
    "\n",
    "    Parameters:\n",
    "    data1, data2\n",
    "\n",
    "    Returns:\n",
    "    Pearson correlation coefficient, p-value of non-correlation test\n",
    "    '''\n",
    "    x, y = np.array(data1), np.array(data2)\n",
    "    r, p_value = scipy.stats.pearsonr(x, y)\n",
    "    return r, p_value\n",
    "\n",
    "\n",
    "def make_contingency(data1, data2):\n",
    "    '''Make contingency table of two categorical data sets\n",
    "    '''\n",
    "    df = pd.DataFrame({\n",
    "        '_': 0,\n",
    "        'data1': data1,\n",
    "        'data2': data2,\n",
    "    })\n",
    "    contingency_table = df.pivot_table(\n",
    "        values='_',\n",
    "        columns='data1',\n",
    "        index='data2',\n",
    "        aggfunc='count')\n",
    "\n",
    "    return contingency_table\n",
    "\n",
    "\n",
    "def chisq(data1, data2):\n",
    "    '''Chi-squred test for two categorical variables\n",
    "    For example, if `data1` is the blood type of a group of people, `data2` is the gender of the same group of people, are blood type and gender correlated?  Null hypothesis is non-correlation.\n",
    "\n",
    "    Parameters:\n",
    "    data1, data2\n",
    "\n",
    "    Returns:\n",
    "    chi2_score, p-value of non-correlation test\n",
    "\n",
    "    '''\n",
    "    contingency_table = make_contingency(data1, data2)\n",
    "    chi2, p_value, _, _ = scipy.stats.chi2_contingency(contingency_table)\n",
    "    return chi2, p_value\n",
    "\n",
    "\n",
    "def joint_entropy(x, y):\n",
    "    '''Joint entropy of two categorical variables.\n",
    "    '''\n",
    "    df = pd.DataFrame(np.stack((x, y), axis=1))\n",
    "    df.columns = ['a', 'b']\n",
    "    df_value_counts_joined = df.groupby(['a', 'b']).size().reset_index().\\\n",
    "        rename(columns={0:  'count'})\n",
    "    value_counts_joined = df_value_counts_joined['count']\n",
    "    return scipy.stats.entropy(value_counts_joined)\n",
    "\n",
    "\n",
    "def mutual_information(data1, data2):\n",
    "    '''Mutual information of two categorical variables\n",
    "    For example, if `data1` is the blood type of a group of people, `data2` is the gender of the same group of people, are blood type and gender mutually dependent?\n",
    "\n",
    "    Parameters:\n",
    "    data1, data2\n",
    "\n",
    "    Returns:\n",
    "    mutual_information\n",
    "    '''\n",
    "\n",
    "    H1 = scipy.stats.entropy(np.bincount(data1))\n",
    "    H2 = scipy.stats.entropy(np.bincount(data2))\n",
    "    mutual_information = H1 + H2 - joint_entropy(data1, data2)\n",
    "    return mutual_information\n",
    "\n",
    "\n",
    "def _mutual_information_sklearn(data1, data2):\n",
    "    return sklearn.metrics.mutual_info_score(data1, data2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
